The aim of this project is to minimize the time spent for Hops-YARN to commit
a transaction in the MySQL Cluster while at the same time parallelize the
process. This will increase the number of events processed by the
scheduler and the overall cluster utilization. In order to explore
the limits of the current system, different optimization techniques
were examined and evaluated as presented in Chapters
\ref{chap:implementation} and \ref{chap:evaluation}. For that reason a
\emph{Quantitative Research} method was followed. The impact of a new
feature in the system was measured in terms of commit time in the
database, the percentage of events handled by the ResourceManager or
the overall cluster utilization as suited.

The quantitative research method is supported by \emph{deductive}
approach and \emph{experimental} method. Before starting an iteration for
implementing a new feature, a thorough profiling of the
workflow of the system was performed, in order to identify the bottlenecks. Afterwards,
wherever it was possible, a prototype was created of the new
feature and benchmarked to validate any performance
gain. The micro-benchmark gave us an incentive on whether it was worth
investing on that feature or not. In case of a positive feedback,
a concrete version of the feature was implemented and finally the system's
performance was measured. After the completion of one feature, another iteration of the
procedure explained above took place to identify more bottlenecks in the system.

Regarding the data collection method, \emph{experiments} were
conducted throughout the project duration and with \emph{statistics}
data analysis calculation the results are presented in Chapter
\ref{chap:evaluation}. For the purpose of data collection a
cluster operated by SICS was used with seven physical machines and two MySQL
Clusters with four and two nodes respectively. In order for the
results to be \emph{reliable} each experiment run several times and
an average was computed where it was reasonable. Since the experiments took a
some time to finish and produced a lot of valuable data, custom
code to dump these data to files was employed and process them later. For the
\emph{validity} part of the experiments, a simulator was used that
simulated a configurable number of nodes in a Hadoop cluster and
measured in fixed intervals the variables that were interesting for
the system performance. After spawning the ResourceManager and the
ResourceTracker in multiple machines, it starts simulating the
NodeManagers that heartbeat the scheduler. Also, it parses existing
trace files and issues a synthetic workload to the scheduler. The simulator used is a
modified version of the simulator that ships together with the Hadoop
distribution. The difference is that the load of simulating the
NodeManagers and sending application launching requests is distributed across
multiple machines in the cluster. Since the workload is parsed from
trace files, it makes the experiments \emph{reproducible} by other
researchers. A note should be taken here. The performance of the system is affected
by the load of the physical machine, the network traffic and the
utilization of the database, so a small variation on the results
should be anticipated.
